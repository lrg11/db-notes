Elf
The theoretical guarantee why Elf could achieve a notable compression ratio is due to its Eraser step, which transforms a floating-point value to another one with more trailing zeros under a guaranteed bound. This step can potentially improve the compression ratio of most XOR-based compression methods tremendously. The number of erased bits is dependent merely on the decimal significand count ğ›½, and a bigger ğ›½ usually means fewer bits erased. If ğ›½ â‰¤ 14, we can erase at least âŒˆ51âˆ’14Ã—ğ‘™ğ‘œğ‘”210âŒ‰= 5 bits, which always guarantees a positive gain. But if ğ›½ â‰¥ 16, we can only erase at most âŒŠ53âˆ’(16âˆ’1)Ã—ğ‘™ğ‘œğ‘”210âŒ‹=3 bits, leading to a negative gain as it requires at least 4 bits to record ğ›½âˆ—.

Elf is a lossless compression algorithm because it aims to recover the original floating-point values without any precision loss. The erasing step in Elf introduces some precision loss, but it is compensated by the restoring step, which recovers the original values from the erased ones. Furthermore, Elf uses a novel XOR-based compressor to encode the XORed results containing many trailing zeros, which further improves the compression performance without losing any information. Therefore, Elf achieves a notable compression ratio with a theoretical guarantee while maintaining the lossless property.

The efficiency gain that can be benefited from Elf over the best competitor Chimp128 depends on the dataset being compressed and the value of ğ›½. According to the experimental results presented in the paper, if ğ›½ is not large, Elf compression algorithm is even 8.7% âˆ¼33.3% better than the Eraser-enhanced Gorilla and Chimp. In particular, when ğ›½=6, the compression ratio gain of Elf over Chimp128 achieves the highest (33% and 55% relative improvement in a time series dataset and a non-time series dataset, respectively). However, for datasets with large ğ›½, ElfEraser cannot enhance the XOR-based compressors, including Chimp128, because for large ğ›½, ElfEraser gives up erasing to avoid a negative gain. Therefore, the efficiency gain of Elf over Chimp128 depends on the specific dataset and the value of ğ›½.

Elf considers only the neighboring values because it uses an erasing-based lossless floating-point compression algorithm. The algorithm transforms a floating-point value to another one with more trailing zeros under a guaranteed bound. The number of erased bits is dependent merely on the decimal significand count, and a bigger decimal significand count usually means fewer bits erased. Therefore, Elf can only erase a small number of bits for large decimal significand counts, which leads to a negative gain as it requires more bits to record the modified decimal significand count. To ensure a positive gain, Elf only performs erasing when the modified decimal significand count is less than 16 and the number of significant mantissa bits is greater than 4. By considering only the neighboring values, Elf can achieve good compression performance in most real-world scenarios.

ElfXORcmp is effective for several reasons. Firstly, it utilizes a novel approach to compress the first value of a time series, which tends to have a large number of trailing zeros after being erased some insignificant mantissa bits. By recording the number of trailing zeros and storing the non-trailing bits with fewer bits, ElfXORcmp can compress the first value using fewer bits than existing XOR-based compressors.

Secondly, ElfXORcmp borrows some ideas from existing XOR-based compressors such as Gorilla and Chimp, but extends them to achieve a better compression ratio. Specifically, ElfXORcmp stores the XOR difference between the current value and the previous value, similar to most existing XOR-based compressors. However, it also considers only the neighboring values, unlike Chimp 128, which considers 128 earlier values to find the best matched value. This approach can reduce the complexity of maintaining a hash table with a large size.

Overall, ElfXORcmp is effective because it combines a novel approach to compress the first value with an optimized version of existing XOR-based compressors, which can achieve a much better compression ratio than existing XOR-based compressors.